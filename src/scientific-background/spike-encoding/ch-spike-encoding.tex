\subsection{Spike Encoders}

The arena of computational neuroscience has witnessed the advent of diverse methods for data encoding, especially in the transformation of conventional data formats into spatiotemporal patterns known as spike trains. These spike trains, sequences of action potentials, form the fundamental language of neurons and provide an effective medium for data encoding in neural models. The crucial step of converting classic data types into spike trains is pivotal to the functionality of these models, shaping how they perceive, process, and respond to input information.

In the forthcoming sections, we delve into some of the most prevalent techniques employed for encoding typical data types - including pixels from images or scalar values - into spike trains. Our exploration will encompass an array of encoding methods, each with its unique approach to transforming data into a neuronal language, catering to different kinds of applications and data characteristics. 

As we traverse through these encoding methodologies, the emphasis will be on understanding the underlying principles, the strengths and potential limitations of each technique, and their suitability under various contexts. The objective is to equip the reader with a robust comprehension of these encoding strategies, providing a springboard for their application in the development and analysis of neural models.

\input{scientific-background/spike-encoding/ch-rate-encoding}

\input{scientific-background/spike-encoding/ch-latency-encoding}

\input{scientific-background/spike-encoding/ch-population-encoding}
