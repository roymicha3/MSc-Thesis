\subsubsection{Max Time Cross-Entropy} \label{ch:max_time_cross_entropy}

The output layer will reduce the time dimensionality by evaluating the max value of each input voltage:

\begin{equation}
    v_k^{\text{max}} = \max_{t} v_k(t)
\end{equation}

The activation function of the output layer will be the SoftMax function:

\begin{equation}
    p_{\mu}(K_{\mu}=k) = \sigma_k^{\mu} = \frac{\exp(\beta \cdot v_k^{\text{max}})}{\sum_{k'} \exp(\beta \cdot v_{k'}^{\text{max}})}
\end{equation}

The cross-entropy loss:

\begin{equation}
    E(\mathbf{w}) = -\sum_{\mu} \sum_{k=1}^K y_k^{\mu} \ln(\sigma_k^{\mu})
\end{equation}

where \( y_k^{\mu} \) is a one hot vector identifying the label of the \(\mu\)-th sample.
